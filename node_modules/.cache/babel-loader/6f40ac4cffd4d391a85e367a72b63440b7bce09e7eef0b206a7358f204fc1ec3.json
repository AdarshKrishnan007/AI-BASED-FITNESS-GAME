{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { getMainHeaderString as main } from './webgpu_program';\nimport { computeDispatch, flatDispatchLayout } from './webgpu_util';\nexport class ReduceProgram {\n  constructor(reduceInfo, reduceType, maxComputeWorkgroupSizeX) {\n    this.variableNames = ['x'];\n    this.uniforms = 'reduceSize : i32,';\n    this.size = true;\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape] = backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    // If reduceSize |reduceInfo.inSize| is very large, the I/O accessing will\n    // become the bottleneck. Increasing workgroupSize can reduce the times of\n    // accessing global memory. The threshold value is just to make sure the\n    // reduceSize is large enough for a bigger workgroupSize.\n    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {\n      this.workgroupSize = [512, 1, 1];\n    } else if (reduceInfo.inSize >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n    this.reduceType = reduceType;\n    this.shaderKey = \"reduce_\".concat(reduceType);\n  }\n  getUserCode() {\n    let reduceOp = \"\";\n    let initValue = '0.0';\n    const workgroupSizeX = this.workgroupSize[0];\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = \"\\n         if (isnan(candidate)) {\\n          bestValue = uniforms.NAN;\\n         } else if (!isnan(bestValue) && candidate \".concat(this.reduceType === 'min' ? '<' : '>', \" bestValue)\\n           {  bestValue = candidate; }\");\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'all') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'any') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';\n      initValue = '0.0';\n    }\n    const outputSnippet = this.reduceType === 'mean' ? // tslint:disable-next-line:max-line-length\n    \"setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));\" : \"setOutputAtIndex(outputIndex, bestValue);\";\n    const sharedMemorySnippet = \"\\n         var<workgroup> xBestValues : array<f32, \".concat(workgroupSizeX, \">;\\n       \");\n    const userCode = \"\\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\\n        return ((a - 1u) / b + 1u);\\n       }\\n\\n       \".concat(sharedMemorySnippet, \"\\n       fn getOffset(outputIndex : i32) -> i32 {\\n         let outputCoords = getCoordsFromIndex(outputIndex);\\n         let offset = \").concat(this.outputShape.length === 1 ? 'outputCoords' : 'outputCoords[0]', \" * uniforms.reduceSize;\\n          return offset;\\n       }\\n       \").concat(main('index'), \" {\\n         let outputIndex = index / \").concat(workgroupSizeX, \";\\n         let offset = getOffset(outputIndex);\\n         var bestValue = \").concat(initValue, \";\\n         let Length = uniforms.reduceSize;\\n         let WorkPerThread = DIV_CEIL(u32(Length), \").concat(workgroupSizeX, \"u);\\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\\n             k = k + \").concat(workgroupSizeX, \") {\\n           let candidate = f32(x[offset + k]);\\n           \").concat(reduceOp, \"\\n         }\\n         xBestValues[localId.x] = bestValue;\\n         workgroupBarrier();\\n\\n         var reduceSize = min(u32(Length), \").concat(workgroupSizeX, \"u);\\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\\n             currentSize = reduceSize / 2u) {\\n           let interval = DIV_CEIL(reduceSize, 2u);\\n           if (localId.x < currentSize) {\\n            let candidate = xBestValues[localId.x + interval];\\n            \").concat(reduceOp, \"\\n            xBestValues[localId.x] = bestValue;\\n           }\\n           reduceSize = interval;\\n           workgroupBarrier();\\n         }\\n\\n         if (localId.x == 0u && outputIndex < uniforms.size) {\\n          \").concat(outputSnippet, \"\\n        }\\n       }\\n     \");\n    return userCode;\n  }\n}","map":{"version":3,"names":["backend_util","getMainHeaderString","main","computeDispatch","flatDispatchLayout","ReduceProgram","constructor","reduceInfo","reduceType","maxComputeWorkgroupSizeX","variableNames","uniforms","size","inputShape","batchSize","inSize","outputShape","computeOutAndReduceShapes","length","workgroupSize","dispatchLayout","dispatch","shaderKey","concat","getUserCode","reduceOp","initValue","workgroupSizeX","outputSnippet","sharedMemorySnippet","userCode"],"sources":["D:\\Fitness WebApp\\tfjs-backend-webgpu\\src\\reduce_webgpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'reduceSize : i32,';\n  reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum';\n  inputShape: number[];\n  size = true;\n\n  constructor(\n      reduceInfo: backend_util.ReduceInfo,\n      reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum',\n      maxComputeWorkgroupSizeX: number) {\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape, ] =\n        backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    // If reduceSize |reduceInfo.inSize| is very large, the I/O accessing will\n    // become the bottleneck. Increasing workgroupSize can reduce the times of\n    // accessing global memory. The threshold value is just to make sure the\n    // reduceSize is large enough for a bigger workgroupSize.\n    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {\n      this.workgroupSize = [512, 1, 1];\n    } else if (reduceInfo.inSize >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n\n    this.reduceType = reduceType;\n    this.shaderKey = `reduce_${reduceType}`;\n  }\n\n  getUserCode(): string {\n    let reduceOp = ``;\n    let initValue = '0.0';\n    const workgroupSizeX = this.workgroupSize[0];\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = `\n         if (isnan(candidate)) {\n          bestValue = uniforms.NAN;\n         } else if (!isnan(bestValue) && candidate ${\n          this.reduceType === 'min' ? '<' : '>'} bestValue)\n           {  bestValue = candidate; }`;\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'all') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'any') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';\n      initValue = '0.0';\n    }\n\n    const outputSnippet = this.reduceType === 'mean' ?\n        // tslint:disable-next-line:max-line-length\n        `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` :\n        `setOutputAtIndex(outputIndex, bestValue);`;\n\n    const sharedMemorySnippet = `\n         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n       `;\n\n    const userCode = `\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n       }\n\n       ${sharedMemorySnippet}\n       fn getOffset(outputIndex : i32) -> i32 {\n         let outputCoords = getCoordsFromIndex(outputIndex);\n         let offset = ${\n        this.outputShape.length === 1 ?\n            'outputCoords' :\n            'outputCoords[0]'} * uniforms.reduceSize;\n          return offset;\n       }\n       ${main('index')} {\n         let outputIndex = index / ${workgroupSizeX};\n         let offset = getOffset(outputIndex);\n         var bestValue = ${initValue};\n         let Length = uniforms.reduceSize;\n         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\n             k = k + ${workgroupSizeX}) {\n           let candidate = f32(x[offset + k]);\n           ${reduceOp}\n         }\n         xBestValues[localId.x] = bestValue;\n         workgroupBarrier();\n\n         var reduceSize = min(u32(Length), ${workgroupSizeX}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            ${reduceOp}\n            xBestValues[localId.x] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (localId.x == 0u && outputIndex < uniforms.size) {\n          ${outputSnippet}\n        }\n       }\n     `;\n    return userCode;\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,QAAO,uBAAuB;AAClD,SAAQC,mBAAmB,IAAIC,IAAI,QAAsB,kBAAkB;AAC3E,SAAQC,eAAe,EAAEC,kBAAkB,QAAO,eAAe;AAEjE,OAAM,MAAOC,aAAa;EAYxBC,YACIC,UAAmC,EACnCC,UAAuD,EACvDC,wBAAgC;IATpC,KAAAC,aAAa,GAAG,CAAC,GAAG,CAAC;IACrB,KAAAC,QAAQ,GAAG,mBAAmB;IAG9B,KAAAC,IAAI,GAAG,IAAI;IAMT,IAAI,CAACC,UAAU,GAAG,CAACN,UAAU,CAACO,SAAS,EAAEP,UAAU,CAACQ,MAAM,CAAC;IAC3D,MAAM,CAACC,WAAW,CAAG,GACjBhB,YAAY,CAACiB,yBAAyB,CAAC,IAAI,CAACJ,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IAChE,IAAI,CAACG,WAAW,GAAGA,WAAW,CAACE,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,GAAGF,WAAW;IAC/D;IACA;IACA;IACA;IACA,IAAIT,UAAU,CAACQ,MAAM,IAAI,KAAK,IAAIN,wBAAwB,IAAI,GAAG,EAAE;MACjE,IAAI,CAACU,aAAa,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;KACjC,MAAM,IAAIZ,UAAU,CAACQ,MAAM,IAAI,IAAI,EAAE;MACpC,IAAI,CAACI,aAAa,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;KACjC,MAAM;MACL,IAAI,CAACA,aAAa,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;;IAEjC,IAAI,CAACC,cAAc,GAAGhB,kBAAkB,CAAC,IAAI,CAACY,WAAW,CAAC;IAC1D;IACA;IACA,IAAI,CAACK,QAAQ,GACTlB,eAAe,CAAC,IAAI,CAACiB,cAAc,EAAE,IAAI,CAACJ,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;IAErE,IAAI,CAACR,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACc,SAAS,aAAAC,MAAA,CAAaf,UAAU,CAAE;EACzC;EAEAgB,WAAWA,CAAA;IACT,IAAIC,QAAQ,KAAK;IACjB,IAAIC,SAAS,GAAG,KAAK;IACrB,MAAMC,cAAc,GAAG,IAAI,CAACR,aAAa,CAAC,CAAC,CAAC;IAC5C,IAAI,IAAI,CAACX,UAAU,KAAK,KAAK,IAAI,IAAI,CAACA,UAAU,KAAK,KAAK,EAAE;MAC1DiB,QAAQ,kIAAAF,MAAA,CAIJ,IAAI,CAACf,UAAU,KAAK,KAAK,GAAG,GAAG,GAAG,GAAG,wDACR;MACjCkB,SAAS,GAAG,gBAAgB;KAC7B,MAAM,IAAI,IAAI,CAAClB,UAAU,KAAK,KAAK,IAAI,IAAI,CAACA,UAAU,KAAK,MAAM,EAAE;MAClEiB,QAAQ,GAAG,sCAAsC;KAClD,MAAM,IAAI,IAAI,CAACjB,UAAU,KAAK,MAAM,EAAE;MACrCiB,QAAQ,GAAG,sCAAsC;MACjDC,SAAS,GAAG,KAAK;KAClB,MAAM,IAAI,IAAI,CAAClB,UAAU,KAAK,KAAK,EAAE;MACpCiB,QAAQ,GAAG,0DAA0D;MACrEC,SAAS,GAAG,KAAK;KAClB,MAAM,IAAI,IAAI,CAAClB,UAAU,KAAK,KAAK,EAAE;MACpCiB,QAAQ,GAAG,0DAA0D;MACrEC,SAAS,GAAG,KAAK;;IAGnB,MAAME,aAAa,GAAG,IAAI,CAACpB,UAAU,KAAK,MAAM,GAC5C;IAAA,oHAE2C;IAE/C,MAAMqB,mBAAmB,yDAAAN,MAAA,CACsBI,cAAc,gBACzD;IAEJ,MAAMG,QAAQ,+GAAAP,MAAA,CAKTM,mBAAmB,6IAAAN,MAAA,CAIpB,IAAI,CAACP,WAAW,CAACE,MAAM,KAAK,CAAC,GACzB,cAAc,GACd,iBAAiB,0EAAAK,MAAA,CAGpBrB,IAAI,CAAC,OAAO,CAAC,6CAAAqB,MAAA,CACeI,cAAc,iFAAAJ,MAAA,CAExBG,SAAS,wGAAAH,MAAA,CAEiBI,cAAc,kHAAAJ,MAAA,CAE5CI,cAAc,sEAAAJ,MAAA,CAExBE,QAAQ,6IAAAF,MAAA,CAKwBI,cAAc,ySAAAJ,MAAA,CAM7CE,QAAQ,kOAAAF,MAAA,CAQVK,aAAa,iCAGnB;IACF,OAAOE,QAAQ;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}