{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { activationFnSnippet, biasActivationSnippet } from './activation_util';\nimport { getMainHeaderString as main, typeSnippet } from './webgpu_program';\nimport { computeDispatch, computeWorkgroupInfoForMatMul } from './webgpu_util';\nexport function matMulReadFnSource(transposeA, transposeB) {\n  let fitAOuter = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  let fitBOuter = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  let fitInner = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  let component = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;\n  util.assert(transposeA && component === 1 || !transposeA, () => \"transposeA \".concat(transposeA, \" is not compatible with component size \").concat(component));\n  const sampleA = \"\\n      \".concat(transposeA ? \"value = getA(batch, col, row);\" : \"value = getA(batch, row, col);\", \"\\n\\n    \");\n  const sampleB = transposeB ? \"value = getB(batch, col, row);\" : \"value = getB(batch, row, col);\";\n  return \"\\n  fn mm_readA(batch: i32, row: i32, col: i32) -> \".concat(typeSnippet(component), \" {\\n    var value = \").concat(typeSnippet(component), \"(0.0);\\n    \").concat(fitAOuter && fitInner ? sampleA : \"\\n    \".concat(transposeA ? \"if(row < uniforms.dimAOuter && col < uniforms.dimInner)\" : \"if(row < uniforms.aShape[1] && col < uniforms.aShape[2])\", \"\\n    {\\n      \").concat(sampleA, \"\\n    }\\n    \"), \"\\n    return value;\\n  }\\n\\n  fn mm_readB(batch: i32, row: i32, col: i32) -> \").concat(typeSnippet(component), \" {\\n    var value = \").concat(typeSnippet(component), \"(0.0);\\n    \").concat(sampleB, \"\\n    return value;\\n  }\\n  \");\n}\nexport function matMulReadWriteFnSource(hasBias, activation, transposeA, transposeB) {\n  let fitAOuter = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  let fitBOuter = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : false;\n  let fitInner = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : false;\n  let component = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 1;\n  return \"\\n  \".concat(matMulReadFnSource(transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component), \"\\n  fn mm_write(batch: i32, row: i32, col: i32, valueIn: \").concat(typeSnippet(component), \") {\\n    \").concat(fitAOuter && fitBOuter ? '' : 'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)', \"\\n    {\\n      var value = valueIn;\\n      let coords = vec3<i32>(batch, row, col);\\n      \").concat(biasActivationSnippet(hasBias, activation), \"\\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\\n    }\\n  }\\n  \");\n}\nconst writeDataToSubAVec4Snippet = (transpose, innerElementSize) => {\n  if (transpose) {\n    return \"\\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\\n          kStart + inputRow,\\n          globalRowStart + inputCol * \".concat(innerElementSize, \");\\n        \");\n  } else {\n    return \"\\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\\n          globalRow + innerRow,\\n          kStart + inputCol * \".concat(innerElementSize, \");\\n        \");\n  }\n};\nconst calculateResultSnippet = (transposeA, innerElementSize, rowPerThread, tileInner) => {\n  if (transposeA) {\n    return \"\\n      for (var k = 0; k < \".concat(tileInner, \"; k++) {\\n        let BCached0 = mm_Bsub[k][tileCol];\\n        let ACached0 = mm_Asub[k][localRow];\\n        for (var i = 0; i < \").concat(rowPerThread, \"; i++) {\\n          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);\\n        }\\n      }\");\n  } else {\n    let bCachedStr = '';\n    let accStr = '';\n    for (let i = 0; i < innerElementSize; i++) {\n      bCachedStr += \"let BCached\".concat(i, \" = mm_Bsub[k * \").concat(innerElementSize, \" + \").concat(i, \"][tileCol];\");\n      accStr += \"acc[i] = fma(BCached\".concat(i, \", vec4<f32>(ACached[\").concat(i, \"]), acc[i]);\");\n    }\n    return \"\\n      for (var k = 0; k < \".concat(tileInner / innerElementSize, \"; k++) {\\n        \").concat(bCachedStr, \"\\n        for (var i = 0; i < \").concat(rowPerThread, \"; i++) {\\n          let ACached = mm_Asub[tileRow + i][k];\\n          \").concat(accStr, \"\\n        }\\n      }\");\n  }\n};\nexport function makeMatMulPackedVec4Source(workPerThread, workgroupSize) {\n  let transposeA = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  let tileInner = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 32;\n  let splitK = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  let splitedDimInner = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 32;\n  let broadcastBatch = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : false;\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  util.assert((transposeA && innerElementSize === 4 && workPerThread[1] === 4 || !transposeA && (innerElementSize === 3 || innerElementSize === 4)) && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4, () => \"If transposeA \".concat(transposeA, \" is true, innerElementSize \").concat(innerElementSize, \" and workPerThread[1] \").concat(workPerThread[1], \" must be 4.\\n          Otherwise, innerElementSize \").concat(innerElementSize, \" must be 3 or 4.\\n      tileAWidth \").concat(tileAWidth, \" must be divisible by workgroupSize[0]\").concat(workgroupSize[0], \". tileInner \").concat(tileInner, \" must be divisible by workgroupSize[1] \").concat(workgroupSize[1], \". colPerThread \").concat(workPerThread[0], \" must be 4.\"));\n  return \"\\n  var<workgroup> mm_Asub : array<array<vec\".concat(innerElementSize, \"<f32>, \").concat(tileAWidth / innerElementSize, \">, \").concat(tileAHight, \">;\\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, \").concat(tileBOuter / workPerThread[0], \">, \").concat(tileInner, \">;\\n\\n  \").concat(main(), \" {\\n    let localRow = i32(localId.y);\\n    let tileRow = localRow * \").concat(rowPerThread, \";\\n    let tileCol = i32(localId.x);\\n\\n    let globalRow = i32(globalId.y) * \").concat(rowPerThread, \";\\n    let globalCol = i32(globalId.x) * \").concat(colPerThread, \";\\n    let batch = \").concat(splitK ? '0' : 'i32(globalId.z)', \";\\n    let batchA = \").concat(splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]', \";\\n    let batchB = \").concat(splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]', \";\\n    let globalRowStart = i32(workgroupId.y) * \").concat(tileAOuter, \";\\n\\n    let numTiles = \").concat(splitK ? \"\".concat(Math.ceil(splitedDimInner / tileInner)) : \"(uniforms.dimInner - 1) / \".concat(tileInner, \" + 1\"), \";\\n    var kStart = \").concat(splitK ? \"i32(globalId.z) * \".concat(splitedDimInner) : '0', \";\\n\\n    var acc: array<vec4<f32>, \").concat(rowPerThread, \">;\\n\\n    // Loop over shared dimension.\\n    let tileRowB = localRow * \").concat(rowPerThreadB, \";\\n    for (var t = 0; t < numTiles; t++) {\\n        // Load one tile of A into local memory.\\n        for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n            let inputRow = tileRow + innerRow;\\n            let inputCol = tileCol;\\n            \").concat(writeDataToSubAVec4Snippet(transposeA, innerElementSize), \"\\n        }\\n\\n        // Load one tile of B into local memory.\\n        for (var innerRow = 0; innerRow < \").concat(rowPerThreadB, \"; innerRow++) {\\n            let inputRow = tileRowB + innerRow;\\n            let inputCol = tileCol;\\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);\\n        }\\n        kStart = kStart + \").concat(tileInner, \";\\n        workgroupBarrier();\\n\\n        // Compute acc values for a single thread.\\n        \").concat(calculateResultSnippet(transposeA, innerElementSize, rowPerThread, tileInner), \"\\n        workgroupBarrier();\\n    }\\n\\n    for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\\n    }\\n  }\");\n}\nconst writeDataToSubASnippet = transpose => {\n  if (transpose) {\n    return \"\\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\\n          kStart + inputRow,\\n          globalRowStart + inputCol);\\n        \";\n  } else {\n    return \"\\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\\n          globalRowStart + inputRow,\\n          kStart + inputCol);\\n        \";\n  }\n};\nconst readDataFromSubASnippet = transposeA => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(workPerThread, workgroupSize) {\n  let transposeA = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  let tileInner = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 32;\n  let splitK = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  let splitedDimInner = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 32;\n  let sequentialAccessByThreads = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : false;\n  let broadcastBatch = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : false;\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0, () => \"tileAHight \".concat(tileAHight, \" must be divisible by workgroupSize[1]\").concat(workgroupSize[1], \", tileAWidth \").concat(tileAWidth, \" must be divisible by workgroupSize[0]\").concat(workgroupSize[0], \", tileInner \").concat(tileInner, \" must be divisible by workgroupSize[1]\").concat(workgroupSize[1]));\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  const matmulSnippet = sequentialAccessByThreads ? \"\\n      let localRow = i32(localId.y);\\n      let localCol = i32(localId.x);\\n      let globalRowStart = i32(workgroupId.y) * \".concat(tileAOuter, \";\\n      let globalColStart = i32(workgroupId.x) * \").concat(tileBOuter, \";\\n\\n      // Loop over shared dimension.\\n      for (var t = 0; t < numTiles; t++) {\\n        // Load one tile of A into local memory.\\n        for (var inputRow = localRow; inputRow < \").concat(tileAHight, \"; inputRow = inputRow + \").concat(workgroupSize[1], \") {\\n          for (var inputCol = localCol; inputCol < \").concat(tileAWidth, \"; inputCol = inputCol + \").concat(workgroupSize[0], \") {\\n            \").concat(writeDataToSubASnippet(transposeA), \"\\n          }\\n        }\\n        // Load one tile of B into local memory.\\n        for (var inputRow = localRow; inputRow < \").concat(tileInner, \"; inputRow = inputRow + \").concat(workgroupSize[1], \") {\\n              for (var inputCol = localCol; inputCol < \").concat(tileBOuter, \"; inputCol = inputCol + \").concat(workgroupSize[0], \") {\\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\\n              kStart + inputRow,\\n              globalColStart + inputCol);\\n          }\\n        }\\n        kStart = kStart + \").concat(tileInner, \";\\n        workgroupBarrier();\\n\\n        // Compute acc values for a single thread.\\n        var BCached : array<f32, \").concat(colPerThread, \">;\\n        for (var k = 0; k < \").concat(tileInner, \"; k++) {\\n          for (var inner = 0; inner < \").concat(colPerThread, \"; inner++) {\\n            BCached[inner] = mm_Bsub[k][localCol + inner * \").concat(workgroupSize[0], \"];\\n          }\\n          for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n            let ACached = \").concat(transposeA ? \"mm_Asub[k][localRow + innerRow * \".concat(workgroupSize[1], \"];\") : \"mm_Asub[localRow + innerRow * \".concat(workgroupSize[1], \"][k];\"), \"\\n            for (var innerCol = 0; innerCol < \").concat(colPerThread, \"; innerCol++) {\\n              acc[innerRow][innerCol] =\\n                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\\n            }\\n          }\\n        }\\n        workgroupBarrier();\\n      }\\n      for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n        let gRow = globalRowStart + localRow + innerRow * \").concat(workgroupSize[1], \";\\n        for (var innerCol = 0; innerCol < \").concat(colPerThread, \"; innerCol++) {\\n          let gCol = globalColStart + localCol + innerCol * \").concat(workgroupSize[0], \";\\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\\n        }\\n      }\\n      \") : \"\\n  let tileRow = i32(localId.y) * \".concat(rowPerThread, \";\\n  let tileCol = i32(localId.x) * \").concat(colPerThread, \";\\n\\n  let globalRow = i32(globalId.y) * \").concat(rowPerThread, \";\\n  let globalCol = i32(globalId.x) * \").concat(colPerThread, \";\\n  let globalRowStart = i32(workgroupId.y) * \").concat(tileAOuter, \";\\n\\n  let tileRowA = i32(localId.y) * \").concat(rowPerThreadA, \";\\n  let tileColA = i32(localId.x) * \").concat(colPerThreadA, \";\\n  let tileRowB = i32(localId.y) * \").concat(rowPerThreadB, \";\\n  // Loop over shared dimension.\\n  for (var t = 0; t < numTiles; t++) {\\n    // Load one tile of A into local memory.\\n    for (var innerRow = 0; innerRow < \").concat(rowPerThreadA, \"; innerRow++) {\\n      for (var innerCol = 0; innerCol < \").concat(colPerThreadA, \"; innerCol++) {\\n        let inputRow = tileRowA + innerRow;\\n        let inputCol = tileColA + innerCol;\\n        \").concat(writeDataToSubASnippet(transposeA), \"\\n      }\\n    }\\n\\n    // Load one tile of B into local memory.\\n    for (var innerRow = 0; innerRow < \").concat(rowPerThreadB, \"; innerRow++) {\\n      for (var innerCol = 0; innerCol < \").concat(colPerThread, \"; innerCol++) {\\n        let inputRow = tileRowB + innerRow;\\n        let inputCol = tileCol + innerCol;\\n        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\\n          kStart + inputRow,\\n          globalCol + innerCol);\\n      }\\n    }\\n    kStart = kStart + \").concat(tileInner, \";\\n    workgroupBarrier();\\n\\n    // Compute acc values for a single thread.\\n    var BCached : array<f32, \").concat(colPerThread, \">;\\n    for (var k = 0; k < \").concat(tileInner, \"; k++) {\\n      for (var inner = 0; inner < \").concat(colPerThread, \"; inner++) {\\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\\n      }\\n\\n      for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n        \").concat(readDataFromSubASnippet(transposeA), \"\\n        for (var innerCol = 0; innerCol < \").concat(colPerThread, \"; innerCol++) {\\n          acc[innerRow][innerCol] =\\n              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\\n        }\\n      }\\n    }\\n\\n    workgroupBarrier();\\n  }\\n\\n  for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n    for (var innerCol = 0; innerCol < \").concat(colPerThread, \"; innerCol++) {\\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\\n          acc[innerRow][innerCol]);\\n    }\\n  }\\n  \");\n  return \"\\n    var<workgroup> mm_Asub : array<array<f32, \".concat(tileAWidth, \">, \").concat(tileAHight, \">;\\n    var<workgroup> mm_Bsub : array<array<f32, \").concat(tileBOuter, \">, \").concat(tileInner, \">;\\n\\n    \").concat(main(), \" {\\n      let batch = \").concat(splitK ? '0' : 'i32(globalId.z)', \";\\n      let batchA = \").concat(splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]', \";\\n      let batchB = \").concat(splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]', \";\\n      let numTiles = \").concat(splitK ? \"\".concat(Math.ceil(splitedDimInner / tileInner)) : \"(uniforms.dimInner - 1) / \".concat(tileInner, \" + 1\"), \";\\n      var kStart = \").concat(splitK ? \"i32(globalId.z) * \".concat(splitedDimInner) : '0', \";\\n\\n      var acc : array<array<f32, \").concat(colPerThread, \">, \").concat(rowPerThread, \">;\\n\\n      // Without this initialization strange values show up in acc.\\n      for (var innerRow = 0; innerRow < \").concat(rowPerThread, \"; innerRow++) {\\n        for (var innerCol = 0; innerCol < \").concat(colPerThread, \"; innerCol++) {\\n          acc[innerRow][innerCol] = 0.0;\\n        }\\n      }\\n      \").concat(matmulSnippet, \"\\n    }\\n  \");\n}\nconst readVectorASnippet = transpose => {\n  return transpose ? \"\\n      mm_readA(batchA, colA, globalRow),\\n      mm_readA(batchA, colA + 1, globalRow),\\n      mm_readA(batchA, colA + 2, globalRow),\\n      mm_readA(batchA, colA + 3, globalRow)\\n  \" : \"\\n      mm_readA(batchA, globalRow, colA),\\n      mm_readA(batchA, globalRow, colA + 1),\\n      mm_readA(batchA, globalRow, colA + 2),\\n      mm_readA(batchA, globalRow, colA + 3)\\n  \";\n};\nexport function makeVectorMatrixProductSource(workgroupSize) {\n  let transposeA = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  util.assert(workgroupSize[1] === 1 && workgroupSize[2] === 1, () => \"A linear work group size is required. But got \".concat(workgroupSize, \".\"));\n  const tileSize = workgroupSize[0] * 4;\n  return \"\\n    var<workgroup> mm_Asub : array<vec4<f32>, \".concat(workgroupSize[0], \">;\\n\\n    \").concat(main(), \" {\\n      let tileCol = i32(localId.x);\\n      let globalCol = i32(globalId.x);\\n      let globalRow = i32(globalId.y);\\n\\n      let numTiles = (uniforms.dimInner - 1) / \").concat(tileSize, \" + 1;\\n      let batch = i32(globalId.z);\\n      let batchA = batch % uniforms.aShape[0];\\n      let batchB = batch % uniforms.bShape[0];\\n      // Without this initialization strange values show up in acc.\\n      var acc = 0.0;\\n\\n      // Loop over shared dimension.\\n      for (var t = 0; t < numTiles; t++) {\\n        // Load one tile of A into local memory.\\n        let colA = t * \").concat(tileSize, \" + tileCol * 4;\\n        mm_Asub[tileCol] = vec4<f32>(\").concat(readVectorASnippet(transposeA), \");\\n        workgroupBarrier();\\n\\n        // Compute acc values for a single thread.\\n        for (var k = 0; k < \").concat(tileSize / 4, \"; k++) {\\n          let rowB = t * \").concat(tileSize, \" + k * 4;\\n          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),\\n                              mm_readB(batchB, rowB + 1, globalCol),\\n                              mm_readB(batchB, rowB + 2, globalCol),\\n                              mm_readB(batchB, rowB + 3, globalCol));\\n\\n          let ACached = mm_Asub[k];\\n          acc = acc + dot(ACached, BCached);\\n        }\\n\\n        workgroupBarrier();\\n      }\\n\\n      mm_write(batch, globalRow, globalCol, acc);\\n    }\\n  \");\n}\nexport class MatMulPackedProgram {\n  constructor(aShape, outputShape) {\n    let transposeA = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n    let transposeB = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n    let bias = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;\n    let activation = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : null;\n    let preluActivationWeights = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;\n    let sequentialAccessByThreads = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : false;\n    this.variableNames = ['A', 'B'];\n    this.uniforms = \"dimAOuter : i32, dimBOuter : i32, dimInner : i32,\";\n    this.outputShape = outputShape;\n    this.dispatchLayout = {\n      x: [2],\n      y: [1],\n      z: [0]\n    };\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = (dimInner % 4 === 0 && !transposeA || outputShape[1] % 4 === 0 && transposeA) && outputShape[2] % 4 === 0 && !transposeB;\n    this.outputComponent = this.isVec4 ? 4 : 1;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workgroupSize = [32, 1, 1];\n    } else {\n      const workgroupInfo = computeWorkgroupInfoForMatMul(outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workgroupSize = workgroupInfo.workgroupSize;\n      this.elementsPerThread = workgroupInfo.elementsPerThread;\n    }\n    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] = this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = \"matMulPacked_\".concat(this.elementsPerThread, \"_\").concat(transposeA, \"_\").concat(transposeB, \"_\").concat(this.activation, \"_\").concat(this.fitAOuter, \"_\").concat(this.fitBOuter, \"_\").concat(this.fitInner, \"_\").concat(this.isVec4, \"_\").concat(this.isVectorA, \"_\").concat(this.sequentialAccessByThreads);\n  }\n  getShapeFit(dimAOuter, dimBOuter, dimInner) {\n    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workgroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n  getUserCode() {\n    const userCode = \"\\n      \".concat(activationFnSnippet(this.activation, this.hasPreluActivationWeights, this.isVec4), \"\\n      \").concat(matMulReadWriteFnSource(this.addBias, this.activation, false /* transposeA is implemented in makeMatMulPackedSource */, this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner, this.isVec4 ? 4 : 1), \"\\n      \").concat(this.isVec4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, true) : this.isVectorA ? makeVectorMatrixProductSource(this.workgroupSize, this.transposeA) : makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, this.sequentialAccessByThreads, true), \"\\n    \");\n    return userCode;\n  }\n}","map":{"version":3,"names":["util","activationFnSnippet","biasActivationSnippet","getMainHeaderString","main","typeSnippet","computeDispatch","computeWorkgroupInfoForMatMul","matMulReadFnSource","transposeA","transposeB","fitAOuter","arguments","length","undefined","fitBOuter","fitInner","component","assert","concat","sampleA","sampleB","matMulReadWriteFnSource","hasBias","activation","writeDataToSubAVec4Snippet","transpose","innerElementSize","calculateResultSnippet","rowPerThread","tileInner","bCachedStr","accStr","i","makeMatMulPackedVec4Source","workPerThread","workgroupSize","splitK","splitedDimInner","broadcastBatch","tileAOuter","tileBOuter","tileAWidth","tileAHight","rowPerThreadB","colPerThread","Math","ceil","writeDataToSubASnippet","readDataFromSubASnippet","makeMatMulPackedSource","sequentialAccessByThreads","rowPerThreadA","colPerThreadA","matmulSnippet","readVectorASnippet","makeVectorMatrixProductSource","tileSize","MatMulPackedProgram","constructor","aShape","outputShape","bias","preluActivationWeights","variableNames","uniforms","dispatchLayout","x","y","z","dimInner","isVec4","outputComponent","isVectorA","elementsPerThread","workgroupInfo","dispatch","addBias","hasPreluActivationWeights","push","getShapeFit","shaderKey","dimAOuter","dimBOuter","getUserCode","userCode"],"sources":["D:\\Fitness WebApp\\tfjs-backend-webgpu\\src\\matmul_packed_webgpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupInfoForMatMul} from './webgpu_util';\n\nexport function matMulReadFnSource(\n    transposeA: boolean, transposeB: boolean, fitAOuter = false,\n    fitBOuter = false, fitInner = false, component = 1) {\n  util.assert(\n      transposeA && component === 1 || !transposeA,\n      () => `transposeA ${transposeA} is not compatible with component size ${\n          component}`);\n  const sampleA = `\n      ${\n      transposeA ? `value = getA(batch, col, row);` :\n                   `value = getA(batch, row, col);`}\n\n    `;\n  const sampleB = transposeB ? `value = getB(batch, col, row);` :\n                               `value = getB(batch, row, col);`;\n\n  return `\n  fn mm_readA(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${\n      fitAOuter && fitInner ?\n          sampleA :\n          `\n    ${\n              transposeA ?\n                  `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` :\n                  `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}\n    {\n      ${sampleA}\n    }\n    `}\n    return value;\n  }\n\n  fn mm_readB(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${sampleB}\n    return value;\n  }\n  `;\n}\n\nexport function matMulReadWriteFnSource(\n    hasBias: boolean, activation: backend_util.Activation, transposeA: boolean,\n    transposeB: boolean, fitAOuter = false, fitBOuter = false, fitInner = false,\n    component = 1) {\n  return `\n  ${\n      matMulReadFnSource(\n          transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}\n  fn mm_write(batch: i32, row: i32, col: i32, valueIn: ${\n      typeSnippet(component)}) {\n    ${\n      fitAOuter && fitBOuter ?\n          '' :\n          'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}\n    {\n      var value = valueIn;\n      let coords = vec3<i32>(batch, row, col);\n      ${biasActivationSnippet(hasBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\n    }\n  }\n  `;\n}\n\nconst writeDataToSubAVec4Snippet =\n    (transpose: boolean, innerElementSize: number) => {\n      if (transpose) {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol * ${innerElementSize});\n        `;\n\n      } else {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRow + innerRow,\n          kStart + inputCol * ${innerElementSize});\n        `;\n      }\n    };\n\nconst calculateResultSnippet =\n    (transposeA: boolean, innerElementSize: number, rowPerThread: number,\n     tileInner: number) => {\n      if (transposeA) {\n        return `\n      for (var k = 0; k < ${tileInner}; k++) {\n        let BCached0 = mm_Bsub[k][tileCol];\n        let ACached0 = mm_Asub[k][localRow];\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);\n        }\n      }`;\n      } else {\n        let bCachedStr = '';\n        let accStr = '';\n        for (let i = 0; i < innerElementSize; i++) {\n          bCachedStr += `let BCached${i} = mm_Bsub[k * ${innerElementSize} + ${\n              i}][tileCol];`;\n          accStr +=\n              `acc[i] = fma(BCached${i}, vec4<f32>(ACached[${i}]), acc[i]);`;\n        }\n        return `\n      for (var k = 0; k < ${tileInner / innerElementSize}; k++) {\n        ${bCachedStr}\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          let ACached = mm_Asub[tileRow + i][k];\n          ${accStr}\n        }\n      }`;\n      }\n    };\n\nexport function makeMatMulPackedVec4Source(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    broadcastBatch = false): string {\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  util.assert(\n      ((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n       (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4,\n      () => `If transposeA ${transposeA} is true, innerElementSize ${\n          innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}. tileInner ${\n          tileInner} must be divisible by workgroupSize[1] ${\n          workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);\n  return `\n  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${\n      tileAWidth / innerElementSize}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${\n      tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\n  ${main()} {\n    let localRow = i32(localId.y);\n    let tileRow = localRow * ${rowPerThread};\n    let tileCol = i32(localId.x);\n\n    let globalRow = i32(globalId.y) * ${rowPerThread};\n    let globalCol = i32(globalId.x) * ${colPerThread};\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n    let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n    let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc: array<vec4<f32>, ${rowPerThread}>;\n\n    // Loop over shared dimension.\n    let tileRowB = localRow * ${rowPerThreadB};\n    for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let inputRow = tileRow + innerRow;\n            let inputCol = tileCol;\n            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}\n        }\n\n        // Load one tile of B into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n            let inputRow = tileRowB + innerRow;\n            let inputCol = tileCol;\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        ${\n      calculateResultSnippet(\n          transposeA, innerElementSize, rowPerThread, tileInner)}\n        workgroupBarrier();\n    }\n\n    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n    }\n  }`;\n}\n\nconst writeDataToSubASnippet = (transpose: boolean) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol);\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRowStart + inputRow,\n          kStart + inputCol);\n        `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' :\n\n                      'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    sequentialAccessByThreads = false, broadcastBatch = false): string {\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(\n      tileAHight % workgroupSize[1] === 0 &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0,\n      () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n          workgroupSize[1]}, tileAWidth ${\n          tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}, tileInner ${\n          tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  const matmulSnippet = sequentialAccessByThreads ?\n      `\n      let localRow = i32(localId.y);\n      let localCol = i32(localId.x);\n      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n      let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n          tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n            ${writeDataToSubASnippet(transposeA)}\n          }\n        }\n        // Load one tile of B into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n              for (var inputCol = localCol; inputCol < ${\n          tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n              kStart + inputRow,\n              globalColStart + inputCol);\n          }\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        var BCached : array<f32, ${colPerThread}>;\n        for (var k = 0; k < ${tileInner}; k++) {\n          for (var inner = 0; inner < ${colPerThread}; inner++) {\n            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n          }\n          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let ACached = ${\n          transposeA ?\n              `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n              `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n              acc[innerRow][innerCol] =\n                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n            }\n          }\n        }\n        workgroupBarrier();\n      }\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n        }\n      }\n      ` :\n      `\n  let tileRow = i32(localId.y) * ${rowPerThread};\n  let tileCol = i32(localId.x) * ${colPerThread};\n\n  let globalRow = i32(globalId.y) * ${rowPerThread};\n  let globalCol = i32(globalId.x) * ${colPerThread};\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let tileRowA = i32(localId.y) * ${rowPerThreadA};\n  let tileColA = i32(localId.x) * ${colPerThreadA};\n  let tileRowB = i32(localId.y) * ${rowPerThreadB};\n  // Loop over shared dimension.\n  for (var t = 0; t < numTiles; t++) {\n    // Load one tile of A into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {\n        let inputRow = tileRowA + innerRow;\n        let inputCol = tileColA + innerCol;\n        ${writeDataToSubASnippet(transposeA)}\n      }\n    }\n\n    // Load one tile of B into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n        let inputRow = tileRowB + innerRow;\n        let inputCol = tileCol + innerCol;\n        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n          kStart + inputRow,\n          globalCol + innerCol);\n      }\n    }\n    kStart = kStart + ${tileInner};\n    workgroupBarrier();\n\n    // Compute acc values for a single thread.\n    var BCached : array<f32, ${colPerThread}>;\n    for (var k = 0; k < ${tileInner}; k++) {\n      for (var inner = 0; inner < ${colPerThread}; inner++) {\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\n      }\n\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        ${readDataFromSubASnippet(transposeA)}\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] =\n              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n        }\n      }\n    }\n\n    workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n          acc[innerRow][innerCol]);\n    }\n  }\n  `;\n\n  return `\n    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;\n    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n    ${main()} {\n      let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n      let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n      let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n      let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;\n\n      // Without this initialization strange values show up in acc.\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] = 0.0;\n        }\n      }\n      ${matmulSnippet}\n    }\n  `;\n}\n\nconst readVectorASnippet = (transpose: boolean) => {\n  return transpose ? `\n      mm_readA(batchA, colA, globalRow),\n      mm_readA(batchA, colA + 1, globalRow),\n      mm_readA(batchA, colA + 2, globalRow),\n      mm_readA(batchA, colA + 3, globalRow)\n  ` :\n                     `\n      mm_readA(batchA, globalRow, colA),\n      mm_readA(batchA, globalRow, colA + 1),\n      mm_readA(batchA, globalRow, colA + 2),\n      mm_readA(batchA, globalRow, colA + 3)\n  `;\n};\n\nexport function makeVectorMatrixProductSource(\n    workgroupSize: [number, number, number], transposeA = false): string {\n  util.assert(\n      workgroupSize[1] === 1 && workgroupSize[2] === 1,\n      () => `A linear work group size is required. But got ${workgroupSize}.`);\n  const tileSize = workgroupSize[0] * 4;\n  return `\n    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;\n\n    ${main()} {\n      let tileCol = i32(localId.x);\n      let globalCol = i32(globalId.x);\n      let globalRow = i32(globalId.y);\n\n      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;\n      let batch = i32(globalId.z);\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      // Without this initialization strange values show up in acc.\n      var acc = 0.0;\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        let colA = t * ${tileSize} + tileCol * 4;\n        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < ${tileSize / 4}; k++) {\n          let rowB = t * ${tileSize} + k * 4;\n          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),\n                              mm_readB(batchB, rowB + 1, globalCol),\n                              mm_readB(batchB, rowB + 2, globalCol),\n                              mm_readB(batchB, rowB + 3, globalCol));\n\n          let ACached = mm_Asub[k];\n          acc = acc + dot(ACached, BCached);\n        }\n\n        workgroupBarrier();\n      }\n\n      mm_write(batch, globalRow, globalCol, acc);\n    }\n  `;\n}\n\nexport class MatMulPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileInner: number;\n  isVectorA: boolean;\n  isVec4: boolean;\n  outputComponent: number;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      aShape: [number, number, number], outputShape: [number, number, number],\n      transposeA = false, transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null,\n      sequentialAccessByThreads = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = ((dimInner % 4 === 0 && !transposeA) ||\n                   (outputShape[1] % 4 === 0 && transposeA)) &&\n        outputShape[2] % 4 === 0 && !transposeB;\n    this.outputComponent = this.isVec4 ? 4 : 1;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workgroupSize = [32, 1, 1];\n    } else {\n      const workgroupInfo = computeWorkgroupInfoForMatMul(\n          outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workgroupSize = workgroupInfo.workgroupSize;\n      this.elementsPerThread = workgroupInfo.elementsPerThread;\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] =\n        this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${\n        transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${\n        this.fitInner}_${this.isVec4}_${this.isVectorA}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getShapeFit(dimAOuter: number, dimBOuter: number, dimInner: number):\n      boolean[] {\n    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workgroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, this.isVec4)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation,\n            false /* transposeA is implemented in makeMatMulPackedSource */,\n            this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.isVec4 ? 4 : 1)}\n      ${\n        this.isVec4 ?\n            makeMatMulPackedVec4Source(\n                this.elementsPerThread, this.workgroupSize, this.transposeA,\n                this.tileInner, false, null, true) :\n            (this.isVectorA ? makeVectorMatrixProductSource(\n                                  this.workgroupSize, this.transposeA) :\n                              makeMatMulPackedSource(\n                                  this.elementsPerThread, this.workgroupSize,\n                                  this.transposeA, this.tileInner, false, null,\n                                  this.sequentialAccessByThreads, true))}\n    `;\n    return userCode;\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAkCA,IAAI,QAAO,uBAAuB;AAEpE,SAAQC,mBAAmB,EAAEC,qBAAqB,QAAO,mBAAmB;AAC5E,SAAQC,mBAAmB,IAAIC,IAAI,EAAEC,WAAW,QAAsB,kBAAkB;AACxF,SAAQC,eAAe,EAAEC,6BAA6B,QAAO,eAAe;AAE5E,OAAM,SAAUC,kBAAkBA,CAC9BC,UAAmB,EAAEC,UAAmB,EACU;EAAA,IADRC,SAAS,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAC3DG,SAAS,GAAAH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAEI,QAAQ,GAAAJ,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAEK,SAAS,GAAAL,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC;EACpDZ,IAAI,CAACkB,MAAM,CACPT,UAAU,IAAIQ,SAAS,KAAK,CAAC,IAAI,CAACR,UAAU,EAC5C,oBAAAU,MAAA,CAAoBV,UAAU,6CAAAU,MAAA,CAC1BF,SAAS,CAAE,CAAC;EACpB,MAAMG,OAAO,cAAAD,MAAA,CAETV,UAAU,sEACmC,aAE9C;EACH,MAAMY,OAAO,GAAGX,UAAU,sEACmC;EAE7D,6DAAAS,MAAA,CACiDd,WAAW,CAACY,SAAS,CAAC,0BAAAE,MAAA,CACvDd,WAAW,CAACY,SAAS,CAAC,kBAAAE,MAAA,CAElCR,SAAS,IAAIK,QAAQ,GACjBI,OAAO,YAAAD,MAAA,CAGHV,UAAU,yHAEoD,qBAAAU,MAAA,CAEpEC,OAAO,kBAEV,mFAAAD,MAAA,CAI8Cd,WAAW,CAACY,SAAS,CAAC,0BAAAE,MAAA,CACvDd,WAAW,CAACY,SAAS,CAAC,kBAAAE,MAAA,CAClCE,OAAO;AAIb;AAEA,OAAM,SAAUC,uBAAuBA,CACnCC,OAAgB,EAAEC,UAAmC,EAAEf,UAAmB,EAC1EC,UAAmB,EACN;EAAA,IADQC,SAAS,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAEG,SAAS,GAAAH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAEI,QAAQ,GAAAJ,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAC3EK,SAAS,GAAAL,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC;EACf,cAAAO,MAAA,CAEIX,kBAAkB,CACdC,UAAU,EAAEC,UAAU,EAAEC,SAAS,EAAEI,SAAS,EAAEC,QAAQ,EAAEC,SAAS,CAAC,+DAAAE,MAAA,CAEtEd,WAAW,CAACY,SAAS,CAAC,eAAAE,MAAA,CAEtBR,SAAS,IAAII,SAAS,GAClB,EAAE,GACF,2DAA2D,iGAAAI,MAAA,CAI7DjB,qBAAqB,CAACqB,OAAO,EAAEC,UAAU,CAAC;AAKlD;AAEA,MAAMC,0BAA0B,GAC5BA,CAACC,SAAkB,EAAEC,gBAAwB,KAAI;EAC/C,IAAID,SAAS,EAAE;IACb,wIAAAP,MAAA,CAGgCQ,gBAAgB;GAGjD,MAAM;IACL,mIAAAR,MAAA,CAGwBQ,gBAAgB;;AAG5C,CAAC;AAEL,MAAMC,sBAAsB,GACxBA,CAACnB,UAAmB,EAAEkB,gBAAwB,EAAEE,YAAoB,EACnEC,SAAiB,KAAI;EACpB,IAAIrB,UAAU,EAAE;IACd,sCAAAU,MAAA,CACoBW,SAAS,uIAAAX,MAAA,CAGPU,YAAY;GAInC,MAAM;IACL,IAAIE,UAAU,GAAG,EAAE;IACnB,IAAIC,MAAM,GAAG,EAAE;IACf,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGN,gBAAgB,EAAEM,CAAC,EAAE,EAAE;MACzCF,UAAU,kBAAAZ,MAAA,CAAkBc,CAAC,qBAAAd,MAAA,CAAkBQ,gBAAgB,SAAAR,MAAA,CAC3Dc,CAAC,gBAAa;MAClBD,MAAM,2BAAAb,MAAA,CACqBc,CAAC,0BAAAd,MAAA,CAAuBc,CAAC,iBAAc;;IAEpE,sCAAAd,MAAA,CACoBW,SAAS,GAAGH,gBAAgB,wBAAAR,MAAA,CAC9CY,UAAU,oCAAAZ,MAAA,CACUU,YAAY,4EAAAV,MAAA,CAE9Ba,MAAM;;AAId,CAAC;AAEL,OAAM,SAAUE,0BAA0BA,CACtCC,aAAuB,EAAEC,aAAuC,EAE1C;EAAA,IADtB3B,UAAU,GAAAG,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAEkB,SAAS,GAAAlB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,EAAE;EAAA,IAAEyB,MAAM,GAAAzB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAE0B,eAAe,GAAA1B,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,EAAE;EAAA,IACxE2B,cAAc,GAAA3B,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EACxB,MAAM4B,UAAU,GAAGJ,aAAa,CAAC,CAAC,CAAC,GAAGD,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMM,UAAU,GAAGL,aAAa,CAAC,CAAC,CAAC,GAAGD,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMO,UAAU,GAAGjC,UAAU,GAAG+B,UAAU,GAAGV,SAAS;EACtD,MAAMa,UAAU,GAAGlC,UAAU,GAAGqB,SAAS,GAAGU,UAAU;EACtD,MAAMb,gBAAgB,GAAGe,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMQ,aAAa,GAAGd,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC;EAClD,MAAMP,YAAY,GAAGM,aAAa,CAAC,CAAC,CAAC;EACrC,MAAMU,YAAY,GAAGV,aAAa,CAAC,CAAC,CAAC;EACrCnC,IAAI,CAACkB,MAAM,CACP,CAAET,UAAU,IAAIkB,gBAAgB,KAAK,CAAC,IAAIQ,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAC9D,CAAC1B,UAAU,KAAKkB,gBAAgB,KAAK,CAAC,IAAIA,gBAAgB,KAAK,CAAC,CAAE,KAChEe,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IACnCN,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAAID,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EAChE,uBAAAhB,MAAA,CAAuBV,UAAU,iCAAAU,MAAA,CAC7BQ,gBAAgB,4BAAAR,MAAA,CAAyBgB,aAAa,CAAC,CAAC,CAAC,yDAAAhB,MAAA,CAC3BQ,gBAAgB,yCAAAR,MAAA,CACrCuB,UAAU,4CAAAvB,MAAA,CACnBiB,aAAa,CAAC,CAAC,CAAC,kBAAAjB,MAAA,CAChBW,SAAS,6CAAAX,MAAA,CACTiB,aAAa,CAAC,CAAC,CAAC,qBAAAjB,MAAA,CAAkBgB,aAAa,CAAC,CAAC,CAAC,gBAAa,CAAC;EACxE,sDAAAhB,MAAA,CAC0CQ,gBAAgB,aAAAR,MAAA,CACtDuB,UAAU,GAAGf,gBAAgB,SAAAR,MAAA,CAAMwB,UAAU,4DAAAxB,MAAA,CAE7CsB,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,SAAAhB,MAAA,CAAMW,SAAS,cAAAX,MAAA,CAE9Cf,IAAI,EAAE,2EAAAe,MAAA,CAEqBU,YAAY,oFAAAV,MAAA,CAGHU,YAAY,+CAAAV,MAAA,CACZ0B,YAAY,yBAAA1B,MAAA,CAClCkB,MAAM,GAAG,GAAG,GAAG,iBAAiB,0BAAAlB,MAAA,CAE5CkB,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B,0BAAApB,MAAA,CAElEkB,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B,uDAAApB,MAAA,CACxBqB,UAAU,8BAAArB,MAAA,CAGpDkB,MAAM,MAAAlB,MAAA,CAAM2B,IAAI,CAACC,IAAI,CAACT,eAAe,GAAGR,SAAS,CAAC,iCAAAX,MAAA,CACZW,SAAS,SAAM,0BAAAX,MAAA,CACxCkB,MAAM,wBAAAlB,MAAA,CAAwBmB,eAAe,IAAK,GAAG,yCAAAnB,MAAA,CAExCU,YAAY,8EAAAV,MAAA,CAGZyB,aAAa,+IAAAzB,MAAA,CAGDU,YAAY,wHAAAV,MAAA,CAG1CM,0BAA0B,CAAChB,UAAU,EAAEkB,gBAAgB,CAAC,iHAAAR,MAAA,CAI1ByB,aAAa,6OAAAzB,MAAA,CAK7BW,SAAS,oGAAAX,MAAA,CAK/BS,sBAAsB,CAClBnB,UAAU,EAAEkB,gBAAgB,EAAEE,YAAY,EAAEC,SAAS,CAAC,oFAAAX,MAAA,CAIxBU,YAAY;AAIpD;AAEA,MAAMmB,sBAAsB,GAAItB,SAAkB,IAAI;EACpD,IAAIA,SAAS,EAAE;IACb;GAMD,MAAM;IACL;;AAMJ,CAAC;AAED,MAAMuB,uBAAuB,GAAIxC,UAAmB,IAAI;EACtD,OAAOA,UAAU,GAAG,+CAA+C,GAE/C,+CAA+C;AACrE,CAAC;AAED;AACA;AACA,OAAM,SAAUyC,sBAAsBA,CAClCf,aAAuB,EAAEC,aAAuC,EAEP;EAAA,IADzD3B,UAAU,GAAAG,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAEkB,SAAS,GAAAlB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,EAAE;EAAA,IAAEyB,MAAM,GAAAzB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAE0B,eAAe,GAAA1B,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,EAAE;EAAA,IACxEuC,yBAAyB,GAAAvC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAAA,IAAE2B,cAAc,GAAA3B,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAC3D,MAAM4B,UAAU,GAAGL,aAAa,CAAC,CAAC,CAAC,GAAGC,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMK,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,GAAGC,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMM,UAAU,GAAGjC,UAAU,GAAG+B,UAAU,GAAGV,SAAS;EACtD,MAAMa,UAAU,GAAGlC,UAAU,GAAGqB,SAAS,GAAGU,UAAU;EACtDxC,IAAI,CAACkB,MAAM,CACPyB,UAAU,GAAGP,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAC/BM,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IACnCN,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EACtC,oBAAAjB,MAAA,CAAoBwB,UAAU,4CAAAxB,MAAA,CAC1BiB,aAAa,CAAC,CAAC,CAAC,mBAAAjB,MAAA,CAChBuB,UAAU,4CAAAvB,MAAA,CACViB,aAAa,CAAC,CAAC,CAAC,kBAAAjB,MAAA,CAChBW,SAAS,4CAAAX,MAAA,CAAyCiB,aAAa,CAAC,CAAC,CAAC,CAAE,CAAC;EAC7E,MAAMgB,aAAa,GAAGT,UAAU,GAAGP,aAAa,CAAC,CAAC,CAAC;EACnD,MAAMiB,aAAa,GAAGX,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC;EACnD,MAAMQ,aAAa,GAAGd,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC;EAClD,MAAMP,YAAY,GAAGM,aAAa,CAAC,CAAC,CAAC;EACrC,MAAMU,YAAY,GAAGV,aAAa,CAAC,CAAC,CAAC;EACrC,MAAMmB,aAAa,GAAGH,yBAAyB,oIAAAhC,MAAA,CAICqB,UAAU,yDAAArB,MAAA,CACVsB,UAAU,gMAAAtB,MAAA,CAMlDwB,UAAU,8BAAAxB,MAAA,CAA2BiB,aAAa,CAAC,CAAC,CAAC,8DAAAjB,MAAA,CAErDuB,UAAU,8BAAAvB,MAAA,CAA2BiB,aAAa,CAAC,CAAC,CAAC,uBAAAjB,MAAA,CACjD6B,sBAAsB,CAACvC,UAAU,CAAC,mIAAAU,MAAA,CAKtCW,SAAS,8BAAAX,MAAA,CAA2BiB,aAAa,CAAC,CAAC,CAAC,kEAAAjB,MAAA,CAEpDsB,UAAU,8BAAAtB,MAAA,CAA2BiB,aAAa,CAAC,CAAC,CAAC,sMAAAjB,MAAA,CAMnCW,SAAS,6HAAAX,MAAA,CAIF0B,YAAY,sCAAA1B,MAAA,CACjBW,SAAS,sDAAAX,MAAA,CACC0B,YAAY,+EAAA1B,MAAA,CACSiB,aAAa,CAAC,CAAC,CAAC,mEAAAjB,MAAA,CAE/BU,YAAY,iDAAAV,MAAA,CAEhDV,UAAU,uCAAAU,MAAA,CAC8BiB,aAAa,CAAC,CAAC,CAAC,2CAAAjB,MAAA,CACnBiB,aAAa,CAAC,CAAC,CAAC,UAAO,sDAAAjB,MAAA,CACtB0B,YAAY,kQAAA1B,MAAA,CAQlBU,YAAY,iFAAAV,MAAA,CACMiB,aAAa,CAAC,CAAC,CAAC,mDAAAjB,MAAA,CAChC0B,YAAY,mFAAA1B,MAAA,CACMiB,aAAa,CAAC,CAAC,CAAC,4IAAAjB,MAAA,CAM3CU,YAAY,0CAAAV,MAAA,CACZ0B,YAAY,+CAAA1B,MAAA,CAETU,YAAY,6CAAAV,MAAA,CACZ0B,YAAY,qDAAA1B,MAAA,CACJqB,UAAU,6CAAArB,MAAA,CAEpBiC,aAAa,2CAAAjC,MAAA,CACbkC,aAAa,2CAAAlC,MAAA,CACbyB,aAAa,uKAAAzB,MAAA,CAITiC,aAAa,+DAAAjC,MAAA,CACXkC,aAAa,yHAAAlC,MAAA,CAG7C6B,sBAAsB,CAACvC,UAAU,CAAC,8GAAAU,MAAA,CAKJyB,aAAa,+DAAAzB,MAAA,CACX0B,YAAY,8QAAA1B,MAAA,CAQ9BW,SAAS,iHAAAX,MAAA,CAIF0B,YAAY,kCAAA1B,MAAA,CACjBW,SAAS,kDAAAX,MAAA,CACC0B,YAAY,8HAAA1B,MAAA,CAINU,YAAY,+BAAAV,MAAA,CAC5C8B,uBAAuB,CAACxC,UAAU,CAAC,kDAAAU,MAAA,CACD0B,YAAY,sOAAA1B,MAAA,CAUlBU,YAAY,6DAAAV,MAAA,CACV0B,YAAY,4IAKjD;EAED,0DAAA1B,MAAA,CAC8CuB,UAAU,SAAAvB,MAAA,CAAMwB,UAAU,wDAAAxB,MAAA,CAC1BsB,UAAU,SAAAtB,MAAA,CAAMW,SAAS,gBAAAX,MAAA,CAEnEf,IAAI,EAAE,4BAAAe,MAAA,CACQkB,MAAM,GAAG,GAAG,GAAG,iBAAiB,4BAAAlB,MAAA,CAE9CkB,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B,4BAAApB,MAAA,CAElEkB,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B,8BAAApB,MAAA,CAElEkB,MAAM,MAAAlB,MAAA,CAAM2B,IAAI,CAACC,IAAI,CAACT,eAAe,GAAGR,SAAS,CAAC,iCAAAX,MAAA,CACZW,SAAS,SAAM,4BAAAX,MAAA,CACtCkB,MAAM,wBAAAlB,MAAA,CAAwBmB,eAAe,IAAK,GAAG,4CAAAnB,MAAA,CAEvC0B,YAAY,SAAA1B,MAAA,CAAMU,YAAY,yHAAAV,MAAA,CAGvBU,YAAY,iEAAAV,MAAA,CACV0B,YAAY,2FAAA1B,MAAA,CAIhDmC,aAAa;AAGrB;AAEA,MAAMC,kBAAkB,GAAI7B,SAAkB,IAAI;EAChD,OAAOA,SAAS,wXAWf;AACH,CAAC;AAED,OAAM,SAAU8B,6BAA6BA,CACzCpB,aAAuC,EAAoB;EAAA,IAAlB3B,UAAU,GAAAG,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAC7DZ,IAAI,CAACkB,MAAM,CACPkB,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAAIA,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EAChD,uDAAAjB,MAAA,CAAuDiB,aAAa,MAAG,CAAC;EAC5E,MAAMqB,QAAQ,GAAGrB,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC;EACrC,0DAAAjB,MAAA,CAC8CiB,aAAa,CAAC,CAAC,CAAC,gBAAAjB,MAAA,CAE1Df,IAAI,EAAE,gLAAAe,MAAA,CAKqCsC,QAAQ,yYAAAtC,MAAA,CAUhCsC,QAAQ,4DAAAtC,MAAA,CACMoC,kBAAkB,CAAC9C,UAAU,CAAC,yHAAAU,MAAA,CAIvCsC,QAAQ,GAAG,CAAC,yCAAAtC,MAAA,CACfsC,QAAQ;AAgBnC;AAEA,OAAM,MAAOC,mBAAmB;EAuB9BC,YACIC,MAAgC,EAAEC,WAAqC,EAItC;IAAA,IAHjCpD,UAAU,GAAAG,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IAAA,IAAEF,UAAU,GAAAE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IAAA,IAAEkD,IAAA,GAAAlD,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAmB,IAAI;IAAA,IAC/DY,UAAA,GAAAZ,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAsC,IAAI;IAAA,IAC1CmD,sBAAA,GAAAnD,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAqC,IAAI;IAAA,IACzCuC,yBAAyB,GAAAvC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IAvBrC,KAAAoD,aAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC;IAC1B,KAAAC,QAAQ,sDAAsD;IAuB5D,IAAI,CAACJ,WAAW,GAAGA,WAAW;IAC9B,IAAI,CAACK,cAAc,GAAG;MAACC,CAAC,EAAE,CAAC,CAAC,CAAC;MAAEC,CAAC,EAAE,CAAC,CAAC,CAAC;MAAEC,CAAC,EAAE,CAAC,CAAC;IAAC,CAAC;IAC9C,MAAMC,QAAQ,GAAG7D,UAAU,GAAGmD,MAAM,CAAC,CAAC,CAAC,GAAGA,MAAM,CAAC,CAAC,CAAC;IACnD,IAAI,CAACW,MAAM,GAAG,CAAED,QAAQ,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC7D,UAAU,IACjCoD,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAIpD,UAAW,KACnDoD,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAACnD,UAAU;IAC3C,IAAI,CAAC8D,eAAe,GAAG,IAAI,CAACD,MAAM,GAAG,CAAC,GAAG,CAAC;IAC1C,IAAI,CAACE,SAAS,GAAGZ,WAAW,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAACpD,UAAU;IAEpD,IAAI,CAAC,IAAI,CAAC8D,MAAM,IAAI,IAAI,CAACE,SAAS,EAAE;MAClC;MACA,IAAI,CAACC,iBAAiB,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;MAClC,IAAI,CAACtC,aAAa,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;KAChC,MAAM;MACL,MAAMuC,aAAa,GAAGpE,6BAA6B,CAC/CsD,WAAW,CAAC,CAAC,CAAC,EAAES,QAAQ,EAAET,WAAW,CAAC,CAAC,CAAC,EAAEpD,UAAU,CAAC;MACzD,IAAI,CAAC2B,aAAa,GAAGuC,aAAa,CAACvC,aAAa;MAChD,IAAI,CAACsC,iBAAiB,GAAGC,aAAa,CAACD,iBAAiB;;IAG1D,IAAI,CAACE,QAAQ,GAAGtE,eAAe,CAC3B,IAAI,CAAC4D,cAAc,EAAE,IAAI,CAACL,WAAW,EAAE,IAAI,CAACzB,aAAa,EACzD,IAAI,CAACsC,iBAAiB,CAAC;IAE3B,MAAMG,OAAO,GAAGf,IAAI,IAAI,IAAI;IAC5B,MAAMgB,yBAAyB,GAAGf,sBAAsB,IAAI,IAAI;IAChE,IAAIc,OAAO,EAAE;MACX,IAAI,CAACb,aAAa,CAACe,IAAI,CAAC,MAAM,CAAC;;IAGjC,IAAID,yBAAyB,EAAE;MAC7B,IAAI,CAACd,aAAa,CAACe,IAAI,CAAC,wBAAwB,CAAC;;IAGnD,IAAI,CAAC5B,yBAAyB,GAAGA,yBAAyB;IAC1D,IAAI,CAAC1C,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACmE,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACrD,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACsD,yBAAyB,GAAGA,yBAAyB;IAC1D,CAAC,IAAI,CAACnE,SAAS,EAAE,IAAI,CAACI,SAAS,EAAE,IAAI,CAACC,QAAQ,CAAC,GAC3C,IAAI,CAACgE,WAAW,CAACnB,WAAW,CAAC,CAAC,CAAC,EAAEA,WAAW,CAAC,CAAC,CAAC,EAAES,QAAQ,CAAC;IAC9D,IAAI,CAACW,SAAS,mBAAA9D,MAAA,CAAmB,IAAI,CAACuD,iBAAiB,OAAAvD,MAAA,CAAIV,UAAU,OAAAU,MAAA,CACjET,UAAU,OAAAS,MAAA,CAAI,IAAI,CAACK,UAAU,OAAAL,MAAA,CAAI,IAAI,CAACR,SAAS,OAAAQ,MAAA,CAAI,IAAI,CAACJ,SAAS,OAAAI,MAAA,CACjE,IAAI,CAACH,QAAQ,OAAAG,MAAA,CAAI,IAAI,CAACoD,MAAM,OAAApD,MAAA,CAAI,IAAI,CAACsD,SAAS,OAAAtD,MAAA,CAC9C,IAAI,CAACgC,yBAAyB,CAAE;EACtC;EAEA6B,WAAWA,CAACE,SAAiB,EAAEC,SAAiB,EAAEb,QAAgB;IAEhE,MAAM9B,UAAU,GAAG,IAAI,CAACJ,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAACsC,iBAAiB,CAAC,CAAC,CAAC;IACpE,MAAMjC,UAAU,GAAG,IAAI,CAACL,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAACsC,iBAAiB,CAAC,CAAC,CAAC;IAEpE,IAAI,CAAC,IAAI,CAACH,MAAM,IAAI,IAAI,CAACE,SAAS,EAAE;MAClC;MACA,IAAI,CAAC3C,SAAS,GAAG,IAAI,CAACM,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC;KAC3C,MAAM;MACL,IAAI,CAACN,SAAS,GAAGW,UAAU;;IAG7B,MAAM9B,SAAS,GAAGuE,SAAS,GAAG1C,UAAU,KAAK,CAAC;IAC9C,MAAMzB,SAAS,GAAGoE,SAAS,GAAG1C,UAAU,KAAK,CAAC;IAC9C,MAAMzB,QAAQ,GAAGsD,QAAQ,GAAG,IAAI,CAACxC,SAAS,KAAK,CAAC;IAChD,OAAO,CAACnB,SAAS,EAAEI,SAAS,EAAEC,QAAQ,CAAC;EACzC;EAEAoE,WAAWA,CAAA;IACT,MAAMC,QAAQ,cAAAlE,MAAA,CAEVlB,mBAAmB,CACf,IAAI,CAACuB,UAAU,EAAE,IAAI,CAACsD,yBAAyB,EAAE,IAAI,CAACP,MAAM,CAAC,cAAApD,MAAA,CAEjEG,uBAAuB,CACnB,IAAI,CAACuD,OAAO,EAAE,IAAI,CAACrD,UAAU,EAC7B,KAAK,CAAC,2DACN,IAAI,CAACd,UAAU,EAAE,IAAI,CAACC,SAAS,EAAE,IAAI,CAACI,SAAS,EAAE,IAAI,CAACC,QAAQ,EAC9D,IAAI,CAACuD,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC,cAAApD,MAAA,CAExB,IAAI,CAACoD,MAAM,GACPrC,0BAA0B,CACtB,IAAI,CAACwC,iBAAiB,EAAE,IAAI,CAACtC,aAAa,EAAE,IAAI,CAAC3B,UAAU,EAC3D,IAAI,CAACqB,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,GACrC,IAAI,CAAC2C,SAAS,GAAGjB,6BAA6B,CACzB,IAAI,CAACpB,aAAa,EAAE,IAAI,CAAC3B,UAAU,CAAC,GACxCyC,sBAAsB,CAClB,IAAI,CAACwB,iBAAiB,EAAE,IAAI,CAACtC,aAAa,EAC1C,IAAI,CAAC3B,UAAU,EAAE,IAAI,CAACqB,SAAS,EAAE,KAAK,EAAE,IAAI,EAC5C,IAAI,CAACqB,yBAAyB,EAAE,IAAI,CAAE,WACnE;IACD,OAAOkC,QAAQ;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}